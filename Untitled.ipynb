{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=True,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest')  # randomly flip images\n",
    "\n",
    "img = load_img('shubhas1.jpg')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,)+ x.shape)\n",
    "i = 0\n",
    "for batch in datagen.flow(x, save_to_dir='img', save_prefix='khan', save_format='jpg'):\n",
    "    i=i+1\n",
    "    if i >31:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(x, dir_name):\n",
    "    datagen = ImageDataGenerator(\n",
    "            featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=True,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=3,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.2, # Randomly zoom image \n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False,\n",
    "            fill_mode='nearest')  # randomly flip images\n",
    "\n",
    "    x = x.reshape((1,)+ x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, save_to_dir=dir_name, save_prefix=dir_name, save_format='jpg'):\n",
    "        i=i+1\n",
    "        if i >31:\n",
    "            break\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    " \n",
    "# extract a single face from a given photograph\n",
    "def read_image_from_server(filename):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = read_image_from_server('khan.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = image_generator(face, 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import load\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from os.path import isdir\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import savez_compressed\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from io import BytesIO\n",
    "from requests import get\n",
    "from numpy import vstack\n",
    "from numpy import concatenate\n",
    " \n",
    "class OnlineTraining(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # create the detector, using default weights\n",
    "        self.detector = MTCNN()\n",
    "        # load the facenet model\n",
    "        self.model = load_model('facenet_keras.h5')\n",
    "        \n",
    "    def angle_check(self, image, filename, required_size=(160, 160)):\n",
    "        # convert to array\n",
    "        pixels = asarray(image)\n",
    "        # detect faces in the image\n",
    "        results = self.detector.detect_faces(pixels)\n",
    "        # extract the bounding box from the first face\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "        return face_array\n",
    "    \n",
    "    def extract_face(self, filename):\n",
    "        # load image from file save on server\n",
    "        response = get(filename)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        # load image from file\n",
    "        #image = Image.open(filename)\n",
    "        image = image.convert('RGB')\n",
    "        try:\n",
    "            face_array1 = self.angle_check(image, filename)\n",
    "            \n",
    "        except:\n",
    "            try:\n",
    "                image1 = image.rotate(90)\n",
    "                face_array1 = self.angle_check(image1, filename)\n",
    "\n",
    "            except:\n",
    "                image2 = image.rotate(270)\n",
    "                face_array1 = self.angle_check(image2, filename)\n",
    "\n",
    "        return face_array1\n",
    "    \n",
    "    def image_generator(self, x, dir_name):\n",
    "        datagen = ImageDataGenerator(\n",
    "                featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=True,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=3,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                zoom_range = 0.2, # Randomly zoom image \n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False,\n",
    "                fill_mode='nearest')  # randomly flip images\n",
    "\n",
    "        x = x.reshape((1,)+ x.shape)\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, save_to_dir=dir_name, save_prefix=dir_name, save_format='jpg'):\n",
    "            i=i+1\n",
    "            if i >31:\n",
    "                break\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import load\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from os.path import isdir\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import savez_compressed\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from io import BytesIO\n",
    "from requests import get\n",
    "from numpy import vstack\n",
    "from numpy import concatenate\n",
    " \n",
    "class OnlineTraining(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # create the detector, using default weights\n",
    "        self.detector = MTCNN()\n",
    "        # load the facenet model\n",
    "        self.model = load_model('facenet_keras.h5')\n",
    "        \n",
    "    def image_generator(self, x, dir_name):\n",
    "        # to generate images\n",
    "        if os.path.isdir(dir_name) is not True:\n",
    "            os.mkdir(dir_name)\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "                featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=True,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=3,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                zoom_range = 0.2, # Randomly zoom image \n",
    "                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False,\n",
    "                fill_mode='nearest')  # randomly flip images\n",
    "\n",
    "        x = x.reshape((1,)+ x.shape)\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, save_to_dir=dir_name, save_prefix=dir_name, save_format='jpg'):\n",
    "            i=i+1\n",
    "            if i >31:\n",
    "                break\n",
    "        return None\n",
    "      \n",
    "    # extract a single face from a given photograph\n",
    "    def read_image_from_server(self, filename):\n",
    "        # load image from file save on server\n",
    "        response = get(filename)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        # convert to RGB, if needed\n",
    "        image = image.convert('RGB')\n",
    "        face_array = asarray(image)\n",
    "        return face_array\n",
    "    \n",
    "    # load images and extract faces for all images in a directory\n",
    "    def iterate_folder_on_server(self, directory, name):\n",
    "        # path\n",
    "        path = directory + name + '/'\n",
    "        for filename in range(5):\n",
    "            imagename = name +'_'+ str(filename) + '.jpeg'\n",
    "            path1 = os.path.join(path,imagename)\n",
    "            print(path1)\n",
    "            try:\n",
    "                face = self.read_image_from_server(path1)\n",
    "                self.image_generator(face, name)\n",
    "            except: None\n",
    "        return None\n",
    "\n",
    "    def angle_check(self, image, filename, required_size=(160, 160)):\n",
    "        # convert to array\n",
    "        pixels = asarray(image)\n",
    "        # detect faces in the image\n",
    "        results = self.detector.detect_faces(pixels)\n",
    "        # extract the bounding box from the first face\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "        return face_array\n",
    "\n",
    "    def extract_face(self, filename):\n",
    "        # load image from file save on server\n",
    "        #response = get(filename)\n",
    "        #image = Image.open(BytesIO(response.content))\n",
    "        # load image from file\n",
    "        image = Image.open(filename)\n",
    "        image = image.convert('RGB')\n",
    "        try:\n",
    "            face_array1 = self.angle_check(image, filename)\n",
    "            \n",
    "        except:\n",
    "            try:\n",
    "                image1 = image.rotate(90)\n",
    "                face_array1 = self.angle_check(image1, filename)\n",
    "\n",
    "            except:\n",
    "                image2 = image.rotate(270)\n",
    "                face_array1 = self.angle_check(image2, filename)\n",
    "\n",
    "        return face_array1\n",
    "    \n",
    "    # load images and extract faces for all images in a directory\n",
    "    def load_faces(self, directory):\n",
    "        faces = list()\n",
    "        # enumerate files\n",
    "        for filename in listdir(directory):\n",
    "            # path\n",
    "            path = directory + filename\n",
    "            # get face\n",
    "            face = self.extract_face(path)\n",
    "            # store\n",
    "            faces.append(face)\n",
    "        return faces\n",
    "    \n",
    "    # load a dataset that contains one subdir for each class that in turn contains images\n",
    "    def load_dataset(self, directory):\n",
    "        X, y = list(), list()\n",
    "        path = directory + '/'\n",
    "        # load all faces in the subdirectory\n",
    "        faces = self.load_faces(path)\n",
    "        # create labels\n",
    "        labels = [directory for _ in range(len(faces))]\n",
    "        # summarize progress\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), directory))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "        return asarray(X), asarray(y)\n",
    "    \n",
    "    # get the face embedding for one face\n",
    "    def get_embedding1(self,face_pixels):\n",
    "        # scale pixel values\n",
    "        face_pixels = face_pixels.astype('float32')\n",
    "        # standardize pixel values across channels (global)\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std\n",
    "        # transform face into one sample\n",
    "        samples = expand_dims(face_pixels, axis=0)\n",
    "        # make prediction to get embedding\n",
    "        yhat = self.model.predict(samples)\n",
    "        return yhat[0]\n",
    "    \n",
    "    def imageinput(self,name):\n",
    "        traindir = 'http://71.40.116.146:97/faceproject/uploads/'\n",
    "        server_img = self.iterate_folder_on_server(traindir, name)\n",
    "        # load train dataset\n",
    "        trainX, trainy = self.load_dataset(name)\n",
    "        print(trainX.shape, trainy.shape)\n",
    "        # save arrays to one file in compressed format\n",
    "        filename = name + '.npz'\n",
    "        savez_compressed(filename, trainX, trainy)\n",
    "\n",
    "        # convert each face in the train set to an embedding\n",
    "        newTrainX = list()\n",
    "        for face_pixels in trainX:\n",
    "            embedding = self.get_embedding1(face_pixels)\n",
    "            newTrainX.append(embedding)\n",
    "        newTrainX = asarray(newTrainX)\n",
    "        print(newTrainX.shape)\n",
    "        filename1 = name + 'Embedded.npz'\n",
    "        # save arrays to one file in compressed format\n",
    "        savez_compressed(filename1, newTrainX, trainy)\n",
    "        data = load('EmbeddedFaceDataset.npz')\n",
    "        trainX1, trainy1 = data['arr_0'], data['arr_1']\n",
    "        ttx = vstack((trainX1,newTrainX))\n",
    "        tty= concatenate([trainy1, trainy])\n",
    "        savez_compressed('EmbeddedFaceDataset.npz', ttx, tty)\n",
    "        return 'Embedding Done...!' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "on = OnlineTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_0.jpeg\n",
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_1.jpeg\n",
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_2.jpeg\n",
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_3.jpeg\n",
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_4.jpeg\n",
      ">loaded 127 examples for class: Neil_9130\n",
      "(127, 160, 160, 3) (127,)\n",
      "(127, 128)\n"
     ]
    }
   ],
   "source": [
    "a = on.imageinput('Neil_9130')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and extract faces for all images in a directory\n",
    "def iterate_folder_on_server(self, directory, name):\n",
    "    # path\n",
    "    path = directory + name + '/'\n",
    "    for filename in range(3):\n",
    "        imagename = name +'_'+ str(filename) + '.jpeg'\n",
    "        path1 = os.path.join(path,imagename)\n",
    "        print(path1)\n",
    "        try:\n",
    "            face = self.read_image_from_server(path1)\n",
    "            self.image_generator(face, name)\n",
    "        except: None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_0.jpeg\n",
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_1.jpeg\n",
      "http://71.40.116.146:97/faceproject/uploads/Neil_9130/Neil_9130_2.jpeg\n"
     ]
    }
   ],
   "source": [
    "iterate_folder_on_server('http://71.40.116.146:97/faceproject/uploads/','Neil_9130')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
